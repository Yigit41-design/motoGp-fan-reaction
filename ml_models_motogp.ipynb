{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli k√ºt√ºphaneleri y√ºkle\n",
        "!pip install pandas numpy scikit-learn scipy matplotlib seaborn -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Veri Y√ºkleme ve Hazƒ±rlama\n",
        "\n",
        "Bu h√ºcre, MotoGP verilerini y√ºkler veya kaydedilmi≈ü veriyi kullanƒ±r.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Veri klas√∂r√º\n",
        "DATA_DIR = Path(\"ml_data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def load_motogp_data():\n",
        "    \"\"\"\n",
        "    MotoGP verilerini y√ºkle veya kaydedilmi≈ü veriyi kullan\n",
        "    \"\"\"\n",
        "    cache_file = DATA_DIR / \"motogp_full_cache.pkl\"\n",
        "    \n",
        "    # Kaydedilmi≈ü veri varsa y√ºkle\n",
        "    if cache_file.exists():\n",
        "        print(\"‚úÖ Kaydedilmi≈ü MotoGP verisi y√ºkleniyor...\")\n",
        "        with open(cache_file, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        print(f\"   Veri y√ºklendi: {len(data)} satƒ±r, {len(data.columns)} kolon\")\n",
        "        print(f\"   Kolonlar: {list(data.columns[:10])}...\")\n",
        "        return data\n",
        "    \n",
        "    # Ana notebook'tan CSV olarak y√ºkle (eƒüer varsa)\n",
        "    csv_file = Path(\"trends_data\") / \"motogp_full_data.csv\"\n",
        "    if csv_file.exists():\n",
        "        print(\"‚úÖ CSV dosyasƒ±ndan MotoGP verisi y√ºkleniyor...\")\n",
        "        data = pd.read_csv(csv_file)\n",
        "        if 'RaceDate' in data.columns:\n",
        "            data['RaceDate'] = pd.to_datetime(data['RaceDate'])\n",
        "        print(f\"   Veri y√ºklendi: {len(data)} satƒ±r\")\n",
        "        # Kaydet\n",
        "        with open(cache_file, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "        print(f\"   Veri kaydedildi: {cache_file}\")\n",
        "        return data\n",
        "    \n",
        "    # Eƒüer ana notebook'ta motogp_full deƒüi≈ükeni varsa (Jupyter kernel'da)\n",
        "    try:\n",
        "        # Jupyter/IPython ortamƒ±nda √ßalƒ±≈üƒ±yorsak, ana notebook'tan deƒüi≈ükeni al\n",
        "        import sys\n",
        "        if 'ipykernel' in sys.modules or 'IPython' in sys.modules:\n",
        "            # IPython namespace'inden al\n",
        "            try:\n",
        "                from IPython import get_ipython\n",
        "                ipython = get_ipython()\n",
        "                if ipython is not None and 'motogp_full' in ipython.user_ns:\n",
        "                    print(\"‚úÖ Ana notebook'tan motogp_full deƒüi≈ükeni y√ºkleniyor...\")\n",
        "                    data = ipython.user_ns['motogp_full'].copy()\n",
        "                    print(f\"   Veri y√ºklendi: {len(data)} satƒ±r\")\n",
        "                    # Kaydet\n",
        "                    with open(cache_file, 'wb') as f:\n",
        "                        pickle.dump(data, f)\n",
        "                    print(f\"   Veri kaydedildi: {cache_file}\")\n",
        "                    return data\n",
        "            except:\n",
        "                pass\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    print(\"‚ö†Ô∏è  Kaydedilmi≈ü veri bulunamadƒ±.\")\n",
        "    print(\"   L√ºtfen √∂nce ana analiz notebook'unu √ßalƒ±≈ütƒ±rƒ±p motogp_full verisini olu≈üturun.\")\n",
        "    print(\"   Veya a≈üaƒüƒ±daki h√ºcrede veriyi manuel olarak y√ºkleyin.\")\n",
        "    return None\n",
        "\n",
        "# Veriyi y√ºkle\n",
        "motogp_data = load_motogp_data()\n",
        "\n",
        "# Veri y√ºklendiyse √∂nizleme g√∂ster\n",
        "if motogp_data is not None:\n",
        "    print(f\"\\nüìä Veri √ñnizleme:\")\n",
        "    print(f\"   Shape: {motogp_data.shape}\")\n",
        "    print(f\"   Kolonlar ({len(motogp_data.columns)}):\")\n",
        "    for i, col in enumerate(motogp_data.columns):\n",
        "        print(f\"     {i+1}. {col}\")\n",
        "    print(f\"\\n   ƒ∞lk 5 satƒ±r:\")\n",
        "    print(motogp_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Veriyi Hazƒ±rlama ve √ñzellik M√ºhendisliƒüi\n",
        "\n",
        "Hedef deƒüi≈üken: **Relative Increase %** kategorilerine g√∂re sƒ±nƒ±flandƒ±rma\n",
        "- **Low**: < 0% (azalma veya deƒüi≈üim yok)\n",
        "- **Medium**: 0-50% (orta artƒ±≈ü)\n",
        "- **High**: > 50% (y√ºksek artƒ±≈ü)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_ml_data(df):\n",
        "    \"\"\"\n",
        "    MotoGP verisini ML i√ßin hazƒ±rla\n",
        "    \n",
        "    Args:\n",
        "        df: motogp_full DataFrame\n",
        "    \n",
        "    Returns:\n",
        "        X: Feature matrix\n",
        "        y: Target labels\n",
        "        feature_names: Feature isimleri\n",
        "    \"\"\"\n",
        "    # Veriyi kopyala\n",
        "    data = df.copy()\n",
        "    \n",
        "    # NaN deƒüerleri temizle\n",
        "    data = data.dropna(subset=['Relative Increase %', 'Popularity', \n",
        "                               'Career wins_num', 'Career podiums_num', \n",
        "                               'Championships_num'])\n",
        "    \n",
        "    # Sonsuz deƒüerleri temizle\n",
        "    data = data[np.isfinite(data['Relative Increase %'])]\n",
        "    \n",
        "    # Hedef deƒüi≈ükeni kategorilere ayƒ±r\n",
        "    def categorize_increase(increase):\n",
        "        if pd.isna(increase) or not np.isfinite(increase):\n",
        "            return None\n",
        "        if increase < 0:\n",
        "            return 'Low'\n",
        "        elif increase < 50:\n",
        "            return 'Medium'\n",
        "        else:\n",
        "            return 'High'\n",
        "    \n",
        "    data['target_category'] = data['Relative Increase %'].apply(categorize_increase)\n",
        "    data = data.dropna(subset=['target_category'])\n",
        "    \n",
        "    # √ñzellikleri se√ß\n",
        "    feature_cols = [\n",
        "        'Popularity',\n",
        "        'Career wins_num',\n",
        "        'Career podiums_num',\n",
        "        'Championships_num',\n",
        "        'Years_active_len',\n",
        "        'Search Before',\n",
        "        'Trend Difference'\n",
        "    ]\n",
        "    \n",
        "    # Sadece mevcut kolonlarƒ± kullan\n",
        "    available_features = [col for col in feature_cols if col in data.columns]\n",
        "    \n",
        "    X = data[available_features].values\n",
        "    y = data['target_category'].values\n",
        "    \n",
        "    # Label encoding\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    \n",
        "    print(f\"‚úÖ Veri hazƒ±rlandƒ±:\")\n",
        "    print(f\"   √ñrnek sayƒ±sƒ±: {len(X)}\")\n",
        "    print(f\"   √ñzellik sayƒ±sƒ±: {X.shape[1]}\")\n",
        "    print(f\"   √ñzellikler: {available_features}\")\n",
        "    print(f\"   Sƒ±nƒ±f daƒüƒ±lƒ±mƒ±:\")\n",
        "    for label, count in zip(le.classes_, np.bincount(y_encoded)):\n",
        "        print(f\"     {label}: {count}\")\n",
        "    \n",
        "    return X, y_encoded, available_features, le\n",
        "\n",
        "# Veriyi hazƒ±rla (eƒüer motogp_data varsa)\n",
        "if motogp_data is not None:\n",
        "    X, y, feature_names, label_encoder = prepare_ml_data(motogp_data)\n",
        "    \n",
        "    # Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    \n",
        "    # √ñl√ßeklendirme\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Train/Test split yapƒ±ldƒ±:\")\n",
        "    print(f\"   Train: {X_train.shape[0]} √∂rnek\")\n",
        "    print(f\"   Test: {X_test.shape[0]} √∂rnek\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Veri y√ºklenemedi. L√ºtfen √∂nce veriyi y√ºkleyin.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Random Forest Classifier\n",
        "\n",
        "Ana sƒ±nƒ±flandƒ±rƒ±cƒ± model - MotoGP fan reaction kategorilerini tahmin eder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def train_random_forest(X_train, X_test, y_train, y_test, \n",
        "                        n_estimators=100, max_depth=None, random_state=42):\n",
        "    \"\"\"\n",
        "    Random Forest modelini eƒüit\n",
        "    \n",
        "    Args:\n",
        "        X_train, X_test: Eƒüitim ve test √∂zellikleri\n",
        "        y_train, y_test: Eƒüitim ve test etiketleri\n",
        "        n_estimators: Aƒüa√ß sayƒ±sƒ±\n",
        "        max_depth: Maksimum derinlik\n",
        "        random_state: Rastgelelik seed'i\n",
        "    \n",
        "    Returns:\n",
        "        model: Eƒüitilmi≈ü model\n",
        "    \"\"\"\n",
        "    print(\"üå≤ Random Forest eƒüitiliyor...\")\n",
        "    print(f\"   Parametreler: n_estimators={n_estimators}, max_depth={max_depth}\")\n",
        "    \n",
        "    # Model olu≈ütur\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced'  # Sƒ±nƒ±f dengesizliƒüini dikkate al\n",
        "    )\n",
        "    \n",
        "    # Eƒüit\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Tahmin\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    \n",
        "    # Deƒüerlendirme\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Model eƒüitildi!\")\n",
        "    print(f\"   Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"   Test Accuracy: {test_acc:.4f}\")\n",
        "    \n",
        "    # √ñzellik √∂nemleri\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(f\"\\nüìä √ñzellik √ñnemleri:\")\n",
        "    print(feature_importance.to_string(index=False))\n",
        "    \n",
        "    # Classification report\n",
        "    print(f\"\\nüìä Classification Report (Test):\")\n",
        "    print(classification_report(y_test, y_pred_test, \n",
        "                                target_names=label_encoder.classes_))\n",
        "    \n",
        "    # Modeli kaydet\n",
        "    model_file = DATA_DIR / \"random_forest_model.pkl\"\n",
        "    with open(model_file, 'wb') as f:\n",
        "        pickle.dump({\n",
        "            'model': model,\n",
        "            'scaler': scaler,\n",
        "            'label_encoder': label_encoder,\n",
        "            'feature_names': feature_names\n",
        "        }, f)\n",
        "    print(f\"\\nüíæ Model kaydedildi: {model_file}\")\n",
        "    \n",
        "    return model, feature_importance\n",
        "\n",
        "# Modeli eƒüit (eƒüer veri hazƒ±rsa)\n",
        "if 'X_train_scaled' in locals() and 'X_test_scaled' in locals():\n",
        "    rf_model, feature_importance = train_random_forest(\n",
        "        X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "        n_estimators=100, max_depth=10\n",
        "    )\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Veri hazƒ±r deƒüil. L√ºtfen √∂nce veri hazƒ±rlama h√ºcresini √ßalƒ±≈ütƒ±rƒ±n.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Decision Tree Classifier\n",
        "\n",
        "Baseline model - Raporda a√ßƒ±klama ve kar≈üƒ±la≈ütƒ±rma i√ßin kullanƒ±lƒ±r.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_decision_tree(X_train, X_test, y_train, y_test,\n",
        "                       max_depth=5, min_samples_split=10, random_state=42):\n",
        "    \"\"\"\n",
        "    Decision Tree modelini eƒüit (baseline)\n",
        "    \n",
        "    Args:\n",
        "        X_train, X_test: Eƒüitim ve test √∂zellikleri\n",
        "        y_train, y_test: Eƒüitim ve test etiketleri\n",
        "        max_depth: Maksimum derinlik\n",
        "        min_samples_split: Split i√ßin minimum √∂rnek sayƒ±sƒ±\n",
        "        random_state: Rastgelelik seed'i\n",
        "    \n",
        "    Returns:\n",
        "        model: Eƒüitilmi≈ü model\n",
        "    \"\"\"\n",
        "    print(\"üå≥ Decision Tree eƒüitiliyor...\")\n",
        "    print(f\"   Parametreler: max_depth={max_depth}, min_samples_split={min_samples_split}\")\n",
        "    \n",
        "    # Model olu≈ütur\n",
        "    model = DecisionTreeClassifier(\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=random_state,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "    \n",
        "    # Eƒüit\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Tahmin\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    \n",
        "    # Deƒüerlendirme\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Model eƒüitildi!\")\n",
        "    print(f\"   Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"   Test Accuracy: {test_acc:.4f}\")\n",
        "    \n",
        "    # Classification report\n",
        "    print(f\"\\nüìä Classification Report (Test):\")\n",
        "    print(classification_report(y_test, y_pred_test,\n",
        "                                target_names=label_encoder.classes_))\n",
        "    \n",
        "    # Aƒüa√ß g√∂rselle≈ütirme (k√º√ß√ºk derinlik i√ßin)\n",
        "    if max_depth <= 5:\n",
        "        plt.figure(figsize=(20, 10))\n",
        "        plot_tree(model, \n",
        "                  feature_names=feature_names,\n",
        "                  class_names=label_encoder.classes_,\n",
        "                  filled=True,\n",
        "                  rounded=True,\n",
        "                  fontsize=10)\n",
        "        plt.title(\"Decision Tree Visualization\", fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(DATA_DIR / \"decision_tree_visualization.png\", dpi=300, bbox_inches='tight')\n",
        "        print(f\"\\nüìä Aƒüa√ß g√∂rselle≈ütirmesi kaydedildi: {DATA_DIR / 'decision_tree_visualization.png'}\")\n",
        "        plt.show()\n",
        "    \n",
        "    # Modeli kaydet\n",
        "    model_file = DATA_DIR / \"decision_tree_model.pkl\"\n",
        "    with open(model_file, 'wb') as f:\n",
        "        pickle.dump({\n",
        "            'model': model,\n",
        "            'scaler': scaler,\n",
        "            'label_encoder': label_encoder,\n",
        "            'feature_names': feature_names\n",
        "        }, f)\n",
        "    print(f\"\\nüíæ Model kaydedildi: {model_file}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Modeli eƒüit (eƒüer veri hazƒ±rsa)\n",
        "if 'X_train_scaled' in locals() and 'X_test_scaled' in locals():\n",
        "    dt_model = train_decision_tree(\n",
        "        X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "        max_depth=5, min_samples_split=10\n",
        "    )\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Veri hazƒ±r deƒüil. L√ºtfen √∂nce veri hazƒ±rlama h√ºcresini √ßalƒ±≈ütƒ±rƒ±n.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Kar≈üƒ±la≈ütƒ±rmasƒ±\n",
        "\n",
        "Random Forest ve Decision Tree modellerinin performans kar≈üƒ±la≈ütƒ±rmasƒ±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_models(rf_model, dt_model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    ƒ∞ki modeli kar≈üƒ±la≈ütƒ±r\n",
        "    \"\"\"\n",
        "    # Tahminler\n",
        "    rf_pred = rf_model.predict(X_test)\n",
        "    dt_pred = dt_model.predict(X_test)\n",
        "    \n",
        "    # Accuracy\n",
        "    rf_acc = accuracy_score(y_test, rf_pred)\n",
        "    dt_acc = accuracy_score(y_test, dt_pred)\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"MODEL KAR≈ûILA≈ûTIRMASI\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nüìä Test Accuracy:\")\n",
        "    print(f\"   Random Forest: {rf_acc:.4f}\")\n",
        "    print(f\"   Decision Tree: {dt_acc:.4f}\")\n",
        "    print(f\"   Fark: {abs(rf_acc - dt_acc):.4f}\")\n",
        "    \n",
        "    # Confusion matrices\n",
        "    print(f\"\\nüìä Confusion Matrices:\")\n",
        "    print(f\"\\nRandom Forest:\")\n",
        "    print(confusion_matrix(y_test, rf_pred))\n",
        "    print(f\"\\nDecision Tree:\")\n",
        "    print(confusion_matrix(y_test, dt_pred))\n",
        "    \n",
        "    # Kar≈üƒ±la≈ütƒ±rma DataFrame\n",
        "    comparison = pd.DataFrame({\n",
        "        'Model': ['Random Forest', 'Decision Tree'],\n",
        "        'Accuracy': [rf_acc, dt_acc],\n",
        "        'Difference': [rf_acc - dt_acc, dt_acc - rf_acc]\n",
        "    })\n",
        "    \n",
        "    print(f\"\\nüìä Kar≈üƒ±la≈ütƒ±rma Tablosu:\")\n",
        "    print(comparison.to_string(index=False))\n",
        "    \n",
        "    return comparison\n",
        "\n",
        "# Modelleri kar≈üƒ±la≈ütƒ±r (eƒüer her ikisi de eƒüitildiyse)\n",
        "if 'rf_model' in locals() and 'dt_model' in locals():\n",
        "    comparison_df = compare_models(rf_model, dt_model, X_test_scaled, y_test)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Her iki model de eƒüitilmedi. L√ºtfen √∂nce modelleri eƒüitin.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
